{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set loglevel to suppress tensorflow GPU messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import re\n",
    "from itertools import count\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "from config import get_config_kACE\n",
    "from PIL import Image\n",
    "from pcolors import pcolors\n",
    "# import Print_Colors as pcolors\n",
    "# import Print_Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "def fetch(name, patch_size=100, **kwargs):\n",
    "    \"\"\"\n",
    "        Input:\n",
    "            name - dataset name, should be in DATASETS\n",
    "            kwargs - config {key: value} pairs.\n",
    "                     Key should be in DATASET_DEFAULT_CONFIG\n",
    "        Output:\n",
    "            training_data - tf.data.Dataset with (x, y, prior)\n",
    "                            shapes like (inf, patch_size, patch_size, ?)\n",
    "            evaluation_data - tf.data.Dataset with (x, y, change_map)\n",
    "                              shapes (1, h, w, ?)\n",
    "            channels - tuple (c_x, c_y), number of channels for domains x and y\n",
    "    \"\"\"\n",
    "    print('fetch')\n",
    "    # also get the change map\n",
    "    x_im, y_im, target_cm = DATASETS[name](prepare_data[name])\n",
    "\n",
    "    print(f\"{pcolors.yellow}Loading dataset.. x,y,changemap\", x_im.shape, y_im.shape, target_cm.shape, f\"{pcolors.end}\")\n",
    "\n",
    "    # if cpu crop the 10% of the image (central cropping)\n",
    "    if not tf.config.list_physical_devices(\"GPU\"):\n",
    "        dataset = [\n",
    "            tf.image.central_crop(tensor, 0.1) for tensor in [x_im, y_im, target_cm]\n",
    "        ]\n",
    "    else:\n",
    "        dataset = [x_im, y_im, target_cm]\n",
    "\n",
    "    dataset = [tf.expand_dims(tensor, 0) for tensor in dataset]\n",
    "    x, y = dataset[0], dataset[1]\n",
    "\n",
    "    # print(f\"{pcolors.red} dataset shape\", dataset)\n",
    "\n",
    "    print(\"dataset:\", tf.reduce_min(x), tf.reduce_max(y), )\n",
    "    evaluation_data = tf.data.Dataset.from_tensor_slices(tuple(dataset))\n",
    "\n",
    "    c_x, c_y = x_im.shape[-1], y_im.shape[-1]\n",
    "\n",
    "\n",
    "    return x, y, evaluation_data, (c_x, c_y)\n",
    "\n",
    "#############################################\n",
    "def _clip(image):\n",
    "    \"\"\"\n",
    "        Normalize image from R_+ to [-1, 1].\n",
    "\n",
    "        For each channel, clip any value larger than mu + 3sigma,\n",
    "        where mu and sigma are the channel mean and standard deviation.\n",
    "        Scale to [-1, 1] by (2*pixel value)/(max(channel)) - 1\n",
    "\n",
    "        Input:\n",
    "            image - (h, w, c) image array in R_+\n",
    "        Output:\n",
    "            image - (h, w, c) image array normalized within [-1, 1]\n",
    "    \"\"\"\n",
    "    temp = np.reshape(image, (-1, image.shape[-1]))\n",
    "\n",
    "    limits = tf.reduce_mean(temp, 0) + 3.0 * tf.math.reduce_std(temp, 0)\n",
    "    for i, limit in enumerate(limits):\n",
    "        channel = temp[:, i]\n",
    "        channel = tf.clip_by_value(channel, 0, limit)\n",
    "        ma, mi = tf.reduce_max(channel), tf.reduce_min(channel)\n",
    "        channel = 2.0 * ((channel) / (ma)) - 1\n",
    "        temp[:, i] = channel\n",
    "\n",
    "    return tf.reshape(tf.convert_to_tensor(temp, dtype=tf.float32), image.shape)\n",
    "\n",
    "#############################################\n",
    "def _texas(clip=True):\n",
    "    \"\"\" Load Texas dataset from .mat \"\"\"\n",
    "    mat = loadmat(\"data/Texas/Cross-sensor-Bastrop-data.mat\")\n",
    "    print(f\"{pcolors.blue}\",mat.keys())\n",
    "    #It is composed by a Landsat 5 TM as the pre-event image and a Landsat 5 TM, a EO-1 ALI and a Landsat 8 as post-event images. We provide also the ground truth we prepared to evaluate the method.\n",
    "    # 't1_L5', 't2_L5', 't2_ALI', 't2_L8', 'ROI_2', 'ROI_1'\n",
    "    t1 = np.array(mat[\"t1_L5\"], dtype=np.single) #pre-event\n",
    "    t2 = np.array(mat[\"t2_ALI\"], dtype=np.single) \n",
    "    roi = mat[\"ROI_1\"]\n",
    "    print(\"texas: (before clip)\", t1.shape, t2.shape, roi.shape)\n",
    "    if clip:\n",
    "        print(\"clipping\")\n",
    "        t1, t2 = _clip(t1), _clip(t2)\n",
    "        print(f\"{pcolors.cyan}texas (after clip):\", t1.shape, t2.shape, f\"{pcolors.end}\")\n",
    "    change_mask = tf.convert_to_tensor(mat[\"ROI_1\"], dtype=tf.bool)\n",
    "    assert t1.shape[:2] == t2.shape[:2] == change_mask.shape[:2]\n",
    "    if change_mask.ndim == 2:\n",
    "        change_mask = change_mask[..., np.newaxis]\n",
    "    return t1, t2, change_mask\n",
    "\n",
    "#############################################\n",
    "DATASETS = {\n",
    "    \"Texas\": _texas,\n",
    "    # \"California\": _california,\n",
    "    # \"France\": _france,\n",
    "    # \"Italy\": _italy,\n",
    "    # \"UK\": _uk,\n",
    "    # \"Denmark\": _denmark,\n",
    "}\n",
    "prepare_data = {\n",
    "    \"Texas\": True,\n",
    "    \"California\": True,\n",
    "    \"France\": True,\n",
    "    \"Italy\": False,\n",
    "    \"UK\": True,\n",
    "    \"Denmark\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'debug': False, 'clipnorm': 1, 'learning_rate': 0.0001, 'l2_lambda': 1e-06, 'logdir': 'logs/Texas/20210107-115629', 'save_images': True, 'channel_x': [1, 2, 3], 'channel_y': [3, 4, 7], 'filter_': <function decorated_median_filter.<locals>.median_filter2d at 0x7fc6c9f38ea0>, 'final_filter': <function decorated_gaussian_filter.<locals>.gauss_filter at 0x7fc6f0081950>, 'patience': 10, 'minimum improvement': 0.001, 'list_epochs': [2, 2, 1], 'batches': 2, 'batch_size': 2, 'patch_size': 10, 'affinity_batch_size': 10, 'affinity_patch_size': 20, 'affinity_stride': 5, 'epochs': 5, 'cycle_lambda': 1, 'cross_lambda': 1, 'recon_lambda': 1, 'kernels_lambda': 1}\n",
      "fetch\n",
      "\u001b[94m dict_keys(['__header__', '__version__', '__globals__', 't1_L5', 't2_L5', 't2_ALI', 't2_L8', 'ROI_2', 'ROI_1'])\n",
      "texas: (before clip) (1534, 808, 7) (1534, 808, 10) (1534, 808)\n",
      "clipping\n",
      "\u001b[96mtexas (after clip): (1534, 808, 7) (1534, 808, 10) \u001b[0m\n",
      "\u001b[93mLoading dataset.. x,y,changemap (1534, 808, 7) (1534, 808, 10) (1534, 808, 1) \u001b[0m\n",
      "\u001b[95mtexas (before return): (154, 82, 7) (154, 82, 10) \u001b[0m\n",
      "dataset: tf.Tensor(-0.7616062, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "(1, 154, 82, 7) (1, 154, 82, 10)\n"
     ]
    }
   ],
   "source": [
    "# How is it used\n",
    "DATASET=\"Texas\"\n",
    "CONFIG = get_config_kACE(DATASET)\n",
    "print(CONFIG)\n",
    "x_im, y_im, EVALUATE, (C_X, C_Y) = fetch(DATASET, **CONFIG)\n",
    "# mat = tf.squeeze(x_im).numpy()\n",
    "print(x_im.shape, y_im.shape)\n",
    "# img = Image.fromarray(mat[:,:,1] , 'L')\n",
    "# img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 154, 82, 7) (1, 154, 82, 10) 7 10\ntf.Tensor(-0.7616062, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n(1, 154, 82, 1)\n(1, 154, 82, 7) (1, 154, 82, 10) 7 10\nEVALUATE <TensorSliceDataset shapes: ((154, 82, 7), (154, 82, 10), (154, 82, 1)), types: (tf.float32, tf.float32, tf.bool)>\ntf.Tensor(-0.7616062, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# #float32\n",
    "# print(x_im.shape, y_im.shape, C_X, C_Y)\n",
    "# print(tf.math.reduce_min(x_im))\n",
    "# print(tf.math.reduce_max(x_im))\n",
    "# x_im.shape[:-1]\n",
    "# Pu = tf.expand_dims(tf.ones(x_im.shape[:-1], dtype=tf.float32), -1) #everyone but the last axix\n",
    "# #creates an input of 1s like (1, 154, 82, 1)\n",
    "# print(Pu.shape)\n",
    "# print(x_im.shape, y_im.shape, C_X, C_Y)\n",
    "# print(\"EVALUATE\", EVALUATE) #master, slave, ground truth pixels (true false)\n",
    "# print(tf.math.reduce_min(x_im))\n",
    "# print(tf.math.reduce_max(x_im))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "display_name": "Python3 (change_det_caa)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}