{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "# Set loglevel to suppress tensorflow GPU messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import datasets\n",
    "from change_detector import ChangeDetector\n",
    "from image_translation import ImageTranslationNetwork\n",
    "from change_priors import Degree_matrix, ztz, image_in_patches\n",
    "from config import get_config_kACE\n",
    "from decorators import image_to_tensorboard\n",
    "import numpy as np\n",
    "\n",
    "from Code_Aligned_Autoencoders import Kern_AceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fetch\n",
      "texas: (1534, 808, 7) (1534, 808, 10)\n",
      "clipping\n",
      "Picking dim 2\n",
      "Loading dataset.. x,y,changemap (1534, 808, 1) (1534, 808, 1) (1534, 808, 1)\n",
      "dataset: tf.Tensor(-0.566398, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "DATASET=\"Texas\"\n",
    "CONFIG = get_config_kACE(DATASET)\n",
    "x_im, y_im, EVALUATE, (C_X, C_Y) = datasets.fetch(DATASET, dim=1, crop_image=False, **CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 1534, 808, 1) (1, 1534, 808, 1) 1 1\ntf.Tensor(-0.566398, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n(1, 1534, 808, 1)\n(1, 1534, 808, 1) (1, 1534, 808, 1) 1 1\nEVALUATE <TensorSliceDataset shapes: ((1534, 808, 1), (1534, 808, 1), (1534, 808, 1)), types: (tf.float32, tf.float32, tf.bool)>\ntf.Tensor(-0.566398, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#float32\n",
    "print(x_im.shape, y_im.shape, C_X, C_Y)\n",
    "print(tf.math.reduce_min(x_im))\n",
    "print(tf.math.reduce_max(x_im))\n",
    "x_im.shape[:-1]\n",
    "Pu = tf.expand_dims(tf.ones(x_im.shape[:-1], dtype=tf.float32), -1) #everyone but the last axix\n",
    "#creates an input of 1s like (1, 154, 82, 1)\n",
    "print(Pu.shape)\n",
    "print(x_im.shape, y_im.shape, C_X, C_Y)\n",
    "print(\"EVALUATE\", EVALUATE) #master, slave, ground truth pixels (true false)\n",
    "print(tf.math.reduce_min(x_im))\n",
    "print(tf.math.reduce_max(x_im))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "why here?\n"
     ]
    }
   ],
   "source": [
    "# CPU or GPU selection\n",
    "if tf.config.list_physical_devices(\"GPU\") and not CONFIG[\"debug\"]:\n",
    "    C_CODE = 3\n",
    "    print(\"here\")\n",
    "    TRANSLATION_SPEC = {\n",
    "        \"enc_X\": {\"input_chs\": C_X, \"filter_spec\": [50, 50, C_CODE]},\n",
    "        \"enc_Y\": {\"input_chs\": C_Y, \"filter_spec\": [50, 50, C_CODE]},\n",
    "        \"dec_X\": {\"input_chs\": C_CODE, \"filter_spec\": [50, 50, C_X]},\n",
    "        \"dec_Y\": {\"input_chs\": C_CODE, \"filter_spec\": [50, 50, C_Y]},\n",
    "    }\n",
    "else:\n",
    "    print(\"why here?\")\n",
    "    C_CODE = 1\n",
    "    TRANSLATION_SPEC = {\n",
    "        \"enc_X\": {\"input_chs\": C_X, \"filter_spec\": [C_CODE]},\n",
    "        \"enc_Y\": {\"input_chs\": C_Y, \"filter_spec\": [C_CODE]},\n",
    "        \"dec_X\": {\"input_chs\": C_CODE, \"filter_spec\": [C_X]},\n",
    "        \"dec_Y\": {\"input_chs\": C_CODE, \"filter_spec\": [C_Y]},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Change Detector Init\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "print(\"Change Detector Init\")\n",
    "cd = Kern_AceNet(TRANSLATION_SPEC, **CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Training\n",
      "(1, 1534, 808, 1)\n",
      "cohens kappa: -0.13181484\n",
      "total_loss 1.4854898 Target 1.4854898 Left 10\n",
      " 50%|█████     | 1/2 [00:07<00:07,  7.75s/it]cohens kappa: -0.13210654\n",
      "total_loss 1.0496955 Target 1.0496955 Left 10\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.81s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]cohens kappa: -0.13232791\n",
      "total_loss 1.4315213 Target 1.4315213 Left 10\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.77s/it]cohens kappa: -0.1324414\n",
      "total_loss 2.274427 Target 1.4315213 Left 9\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.76s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]cohens kappa: -0.13251781\n",
      "total_loss 1.3018103 Target 1.3018103 Left 10\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print(\"Training\")\n",
    "training_time = 0\n",
    "cross_loss_weight = tf.expand_dims(tf.zeros(x_im.shape[:-1], dtype=tf.float32), -1)\n",
    "print(cross_loss_weight.shape)\n",
    "for epochs in CONFIG[\"list_epochs\"]:\n",
    "    CONFIG.update(epochs=epochs)\n",
    "    tr_gen, dtypes, shapes = datasets._training_data_generator(\n",
    "        x_im[0], y_im[0], cross_loss_weight[0], CONFIG[\"patch_size\"]\n",
    "    )\n",
    "    TRAIN = tf.data.Dataset.from_generator(tr_gen, dtypes, shapes)\n",
    "    TRAIN = TRAIN.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    tr_time, _ = cd.train(TRAIN, evaluation_dataset=EVALUATE, **CONFIG)\n",
    "    for x, y, _ in EVALUATE.batch(1):\n",
    "        alpha = cd([x, y])\n",
    "    cross_loss_weight = 1.0 - alpha\n",
    "    training_time += tr_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cohens kappa: -0.07921803\n",
      "(-0.07921803, 0.81720036) (5, 23.00617996800429, '20210107-131049')\n"
     ]
    }
   ],
   "source": [
    "cd.load_all_weights(cd.log_path)\n",
    "cd.final_evaluate(EVALUATE, **CONFIG)\n",
    "final_kappa = cd.metrics_history[\"cohens kappa\"][-1]\n",
    "final_acc = cd.metrics_history[\"ACC\"][-1]\n",
    "performance = (final_kappa, final_acc)\n",
    "timestamp = cd.timestamp\n",
    "epoch = cd.epoch.numpy()\n",
    "speed = (epoch, training_time, timestamp)\n",
    "del cd\n",
    "gc.collect()\n",
    "print(performance, speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "display_name": "Python3 (change_det_caa)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}